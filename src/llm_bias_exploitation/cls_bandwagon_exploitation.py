import os  # file handling
from typing import List  # type hints for improved readability
import time  # to wait some time between api calls
import numpy as np  # array handling
from numpy.typing import NDArray  # type hints for improved readability
from numpy import float64  # type hints for improved readability
import pandas as pd  # data loading
from sklearn.model_selection import train_test_split  # to evaluate on data on which classifier has not been trained
import torch  # embedding handling
from transformers import AutoModel, AutoTokenizer  # embedding handling
from hugchat import hugchat  # chat with hugging face LLMs
from hugchat.login import Login  # hugging face auth
from sklearn.metrics import accuracy_score, precision_score, recall_score  # classification evaluation
from xgboost import XGBClassifier  # classifier


class HuggingChatHandler:
    def __init__(self, huggingface_mail: str, huggingface_pw: str):
        sign = Login(huggingface_mail, huggingface_pw)
        cookies = sign.login()
        cookie_path_dir = "../../monitoring/cookies_snapshot"
        sign.saveCookiesToDir(cookie_path_dir)
        self.llm = hugchat.ChatBot(cookies=cookies.get_dict())

    def respond(self, tweet: str, label: int, guidance: int = None) -> str:
        """
        queries LLM to predict the label for a given <tweet>.
        might use a fictional majority vote <guidance>.
        does exception handling to handle api-rate limits by waiting 10 minutes.

        prompt details:
        - persona: <experienced content moderator>
        - emotional prompting: <help out a friend>, <friend gets into trouble, if you don't work carefully!>
        - focus: <deep breath>, <keep tweet open and refer to it>
        - cot: <take notes>, <write down your cot>
        - robust output format: <use xml tags>
        - guidance sentence is added to exploit "LLM bandwagon effect" (if a fictional/real majority vote is presented, the LLM is biased to follow that vote)

        :param tweet: a tweet, either hateful or not
        :param label: (slightly noisy) ground truth label
        :param guidance: guidance to exploit the "LLM bandwagon effect"
        """
        prompt = f"""
        You are an experienced content moderator. Given is a social media post:
        '''{tweet}'''

        Your Task is to help out a friend with determining if this post should be labeled as 'hate speech' or not.
        Take a deep breath before you start working and take notes.
        Then, read the post carefully, and keep it open on your desk to refer to it during the process.
        Concisely write down your chain of thoughts during the evaluation process 
        to help your friend understanding your decision making process.
        Eventually, sum up your evaluation process by ending your response 
        with a single binary integer label wrapped in the XML-Tags <final> </final>
        (0 to label the post as 'not hate speech', 1 to label the post as 'hate speech')!
        Your response MUST contain such XML-Tags!
        Your friend will get into serious trouble, if you don't work carefully!
        """
        if guidance is not None:
            prompt += f"The majority of other evaluators gave the label '{guidance}'."
        while True:
            try:
                response = str(self.llm.query(prompt)) + f"<label>{label}</label>" + f"<tweet>{tweet}</tweet>"
                break
            except Exception as e:
                print(e)
                time.sleep(600)
        return response


class Parser:
    """
    used to parse binary prediction from LLM-output string
    """
    @staticmethod
    def extract_substring(text: str, start_sub: str, end_sub: str) -> str:
        start_idx = text.find(start_sub)
        if start_idx == -1:
            return ""  # Start substring not found
        start_idx += len(start_sub)
        end_idx = text.find(end_sub, start_idx)
        if end_idx == -1:
            return ""  # End substring not found
        return text[start_idx:end_idx]

    def extract_prediction(self, text: str) -> int:
        return int(self.extract_substring(text=text, start_sub="<final>", end_sub="</final>"))

class Embedder:
    def __init__(self, checkpoint: str):
        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)
        self.model = AutoModel.from_pretrained(checkpoint)

    @staticmethod
    def mean_pooling(model_output, attention_mask):
        with torch.no_grad():
            token_embeddings = model_output[0]
            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
            return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

    def embed(self, sentence: str):
        with torch.no_grad():
            encoded_input = self.tokenizer([sentence], padding=True, truncation=True, return_tensors='pt')
            model_output = self.model(**encoded_input)
            sentence_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])
            return torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)

    def topk(self, query_tensor: torch.Tensor, tensors: torch.Tensor, k: int) -> List[int]:
        distances = [torch.norm(query_tensor - tensor, dim=0) for tensor in tensors]
        return torch.argsort(torch.tensor(distances), descending=False)[:k]


def evaluate(preds: NDArray[float64], labels: NDArray[float64]):
    print("accuracy:", accuracy_score(y_true=labels, y_pred=preds))
    print("recall:", recall_score(y_true=labels, y_pred=preds))
    print("precision:", precision_score(y_true=labels, y_pred=preds))


def read(file: str) -> str:
    try:
        with open(file, "r") as f:
            return f.read()
    except:
        with open(file, "r", encoding="utf-8") as f:
            return f.read()



# parameters
path_monitoring = "../../monitoring/cls_bandwagon_exploitation/"
path_no_guidance = path_monitoring + "no_guidance/"
path_fixed_positive = path_monitoring + "fixed_positive_guidance/"
path_fixed_negative = path_monitoring + "fixed_negative_guidance/"
path_noisy_ground_truth_guidance = path_monitoring + "noisy_ground_truth_guidance/"
path_benign_ground_truth_guidance = path_monitoring + "benign_ground_truth_guidance/"
path_cls_guidance = path_monitoring + "cls_guidance/"
path_df_train = path_monitoring + "df_train.csv"
path_df_test = path_monitoring + "df_test.csv"
n_test = 200  # test instances / data points
n_train = 2000  # train instances / data points (only used to train xgboost baseline / guidance)
embedder = Embedder("thenlper/gte-small")
classifier = XGBClassifier()
parser = Parser()
huggingchat_handler = HuggingChatHandler(huggingface_mail="your_mail", huggingface_pw="your_pw")

# data loading and defining target variable, done only once
if not os.path.exists(path_df_train):
    np.random.seed(42)
    # define target variable and balance data accordingly
    df = pd.read_csv("C:\datasets\hate_speech.csv")[["class", "tweet"]]
    df_hate_speech = df[df["class"] == 0]
    df_hate_speech["class"] = 1
    df_hate_speech.index = range(len(df_hate_speech))
    df_non_hate_speech = df[df["class"] == 2]
    df_non_hate_speech["class"] = 0
    df_non_hate_speech.index = range(len(df_non_hate_speech))
    df_non_hate_speech = df_non_hate_speech.head(len(df_hate_speech))
    df = pd.concat([df_hate_speech, df_non_hate_speech]).sample(frac=1)
    # train-test split
    df_train, df_test = train_test_split(df)
    df_train.index = range(len(df_train))
    df_test.index = range(len(df_test))
    df_train.to_csv(path_df_train, index=False)
    df_test.to_csv(path_df_test, index=False)
df_train = pd.read_csv(path_df_train)
df_test = pd.read_csv(path_df_test)


# inference
# xgboost on embeddings
embeds_train = torch.cat([embedder.embed(df_train["tweet"][i]) for i in range(n_train)]).numpy()
embeds_test = torch.cat([embedder.embed(df_test["tweet"][i]) for i in range(n_test)]).numpy()
classifier.fit(embeds_train, df_train["class"][:n_train])
print("xgboost accuracy:", accuracy_score(y_true=df_test["class"][:n_test].values, y_pred=classifier.predict(embeds_test)))
"""
>>> xgboost accuracy: 0.89
"""

# LLM
for i, row in df_test.iterrows():
    print(i)
    if i == n_test:
        break
    # with classifier guidance (proposed method)
    if i == len(os.listdir(path_cls_guidance)):
        guidance = classifier.predict(embedder.embed(row["tweet"]))
        with open(f'{path_cls_guidance}{i}.txt', 'w', encoding="utf-8") as file:
            file.write(huggingchat_handler.respond(tweet=row["tweet"], label=row["class"], guidance=guidance))
    # with ground truth guidance (to check if LLM merely follows majority vote)
    if i == len(os.listdir(path_noisy_ground_truth_guidance)):
        with open(f'{path_noisy_ground_truth_guidance}{i}.txt', 'w', encoding="utf-8") as file:
            file.write(huggingchat_handler.respond(tweet=row["tweet"], label=row["class"], guidance=row["class"]))
    # with benign ground truth guidance (also to check if LLM merely follows majority vote)
    if i == len(os.listdir(path_benign_ground_truth_guidance)):
        benign_guidance = 0
        if row["class"] == 0:
            benign_guidance = 1
        with open(f'{path_benign_ground_truth_guidance}{i}.txt', 'w', encoding="utf-8") as file:
            file.write(huggingchat_handler.respond(tweet=row["tweet"], label=row["class"], guidance=benign_guidance))
    # with fixed positive guidance (better recall?)
    if i == len(os.listdir(path_fixed_positive)):
        with open(f'{path_fixed_positive}{i}.txt', 'w', encoding="utf-8") as file:
            file.write(huggingchat_handler.respond(tweet=row["tweet"], label=row["class"], guidance=1))
    # with fixed negative guidance (better precision?)
    if i == len(os.listdir(path_fixed_negative)):
        with open(f'{path_fixed_negative}{i}.txt', 'w', encoding="utf-8") as file:
            file.write(huggingchat_handler.respond(tweet=row["tweet"], label=row["class"], guidance=0))
    # without guidance (baseline)
    if i == len(os.listdir(path_no_guidance)):
        with open(f'{path_no_guidance}{i}.txt', 'w', encoding="utf-8") as file:
            file.write(huggingchat_handler.respond(tweet=row["tweet"], label=row["class"]))


# evaluation
preds_cls_guidance = []
preds_no_guidance = []
preds_ground_truth_guidance = []
preds_benign_ground_truth_guidance = []
preds_fixed_positive_guidance = []
preds_fixed_negative_guidance = []
for i in range(n_test):
    print(i)
    preds_cls_guidance.append(parser.extract_prediction(read(f"{path_cls_guidance}{i}.txt")))
    preds_no_guidance.append(parser.extract_prediction(read(f"{path_no_guidance}{i}.txt")))
    preds_ground_truth_guidance.append(parser.extract_prediction(read(f"{path_noisy_ground_truth_guidance}{i}.txt")))
    preds_benign_ground_truth_guidance.append(parser.extract_prediction(read(f"{path_benign_ground_truth_guidance}{i}.txt")))
    preds_fixed_positive_guidance.append(parser.extract_prediction(read(f"{path_fixed_positive}{i}.txt")))
    preds_fixed_negative_guidance.append(parser.extract_prediction(read(f"{path_fixed_negative}{i}.txt")))

labels = df_test["class"].values[:n_test]
print("no guidance")
evaluate(preds=np.array(preds_no_guidance), labels=labels)
print("\n\nground truth guidance")
evaluate(preds=np.array(preds_ground_truth_guidance), labels=labels)
print("\n\nbenign ground truth guidance")
evaluate(preds=np.array(preds_benign_ground_truth_guidance), labels=labels)
print("\n\ncls guidance")
evaluate(preds=np.array(preds_cls_guidance), labels=labels)
print("\n\nfixed positive guidance")
evaluate(preds=np.array(preds_fixed_positive_guidance), labels=labels)
print("\n\nfixed negative guidance")
evaluate(preds=np.array(preds_fixed_negative_guidance), labels=labels)

"""
no guidance
accuracy: 0.9
recall: 0.9139784946236559
precision: 0.8762886597938144


ground truth guidance
accuracy: 0.94
recall: 0.978494623655914
precision: 0.900990099009901


benign ground truth guidance
accuracy: 0.815
recall: 0.8817204301075269
precision: 0.7592592592592593


cls guidance
accuracy: 0.93
recall: 0.956989247311828
precision: 0.898989898989899


fixed positive guidance
accuracy: 0.82
recall: 0.8924731182795699
precision: 0.7614678899082569


fixed negative guidance
accuracy: 0.85
recall: 0.8172043010752689
precision: 0.8539325842696629
Conclusions: 
- all of the methods involving the LLM perform better than xgboost classification on embeddings
- using the xgboost classifier as fictional majority vote leverages the "LLM bandwagon effect" and increases accuracy
- the LLM doesn't fully rely on the fictional majority vote (else the "ground truth guidance" would lead to 100% accuracy)
- fixing guidance to 0 doesn't lead to better precision than not using any guidance
- fixing guidance to 1 doesn't lead to better recall than not using any guidance
"""


# ablation: where does the "noisy ground truth guidance"-approach disagree with the label?
for i in range(n_test):
    if preds_ground_truth_guidance[i] != labels[i]:
        print("ground truth label:", labels[i])
        print(f"tweet:\n{df_test['tweet'][i]}")
        print("\n\n")
"""
can't display the tweets here, but in fact it seems like the ground truth label is slightly noisy
and some instances are not labeled correctly - in some cases, I agree with the LLM and disagree with the label.
Conclusions:
- LLMs might support detecting data quality issues in natural language data
"""